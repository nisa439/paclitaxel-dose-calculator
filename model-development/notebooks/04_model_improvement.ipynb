{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMFyf0YFdje1uAf/eYeRJb5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"W1B_yRszmE3z"},"outputs":[],"source":["{\n"," \"cells\": [\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"# Paclitaxel Dose Optimization - Model Improvement\\n\",\n","    \"\\n\",\n","    \"This notebook covers:\\n\",\n","    \"1. Loading best model from previous step\\n\",\n","    \"2. Hyperparameter optimization\\n\",\n","    \"3. Ensemble methods\\n\",\n","    \"4. Advanced model techniques\\n\",\n","    \"5. Final model selection\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Import required libraries\\n\",\n","    \"import pandas as pd\\n\",\n","    \"import numpy as np\\n\",\n","    \"import matplotlib.pyplot as plt\\n\",\n","    \"import seaborn as sns\\n\",\n","    \"from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\\n\",\n","    \"from sklearn.preprocessing import StandardScaler\\n\",\n","    \"from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor, BaggingRegressor\\n\",\n","    \"from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\\n\",\n","    \"from sklearn.neural_network import MLPRegressor\\n\",\n","    \"import xgboost as xgb\\n\",\n","    \"import pickle\\n\",\n","    \"import json\\n\",\n","    \"import os\\n\",\n","    \"import warnings\\n\",\n","    \"warnings.filterwarnings('ignore')\\n\",\n","    \"\\n\",\n","    \"print('Libraries imported for model improvement!')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Load data and previous results\\n\",\n","    \"X_enhanced = pd.read_csv('../data/processed/X_enhanced.csv')\\n\",\n","    \"y = pd.read_csv('../data/processed/y_enhanced.csv').squeeze()\\n\",\n","    \"\\n\",\n","    \"# Load previous model info\\n\",\n","    \"with open('../data/processed/model_info.json', 'r') as f:\\n\",\n","    \"    previous_results = json.load(f)\\n\",\n","    \"\\n\",\n","    \"baseline_r2 = previous_results['baseline_r2']\\n\",\n","    \"best_previous_r2 = previous_results['best_r2']\\n\",\n","    \"best_previous_model = previous_results['best_model']\\n\",\n","    \"\\n\",\n","    \"print('Previous Results:')\\n\",\n","    \"print(f'Baseline R²: {baseline_r2:.4f}')\\n\",\n","    \"print(f'Best Previous R²: {best_previous_r2:.4f} ({best_previous_model})')\\n\",\n","    \"print(f'Dataset shape: {X_enhanced.shape}')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Split data (same random state for consistency)\\n\",\n","    \"X_train, X_test, y_train, y_test = train_test_split(\\n\",\n","    \"    X_enhanced, y, test_size=0.2, random_state=42\\n\",\n","    \")\\n\",\n","    \"\\n\",\n","    \"# Scale features\\n\",\n","    \"scaler = StandardScaler()\\n\",\n","    \"X_train_scaled = scaler.fit_transform(X_train)\\n\",\n","    \"X_test_scaled = scaler.transform(X_test)\\n\",\n","    \"\\n\",\n","    \"print(f'Data split completed: {X_train.shape} train, {X_test.shape} test')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"## Hyperparameter Optimization\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Optimize Random Forest\\n\",\n","    \"print('Optimizing Random Forest...')\\n\",\n","    \"\\n\",\n","    \"rf_param_grid = {\\n\",\n","    \"    'n_estimators': [300, 500, 800],\\n\",\n","    \"    'max_depth': [10, 15, 20, None],\\n\",\n","    \"    'min_samples_split': [2, 3, 5],\\n\",\n","    \"    'min_samples_leaf': [1, 2, 3]\\n\",\n","    \"}\\n\",\n","    \"\\n\",\n","    \"rf_grid = RandomizedSearchCV(\\n\",\n","    \"    RandomForestRegressor(random_state=42, n_jobs=-1),\\n\",\n","    \"    rf_param_grid,\\n\",\n","    \"    n_iter=20,\\n\",\n","    \"    cv=3,\\n\",\n","    \"    scoring='r2',\\n\",\n","    \"    random_state=42,\\n\",\n","    \"    n_jobs=-1\\n\",\n","    \")\\n\",\n","    \"\\n\",\n","    \"rf_grid.fit(X_train, y_train)\\n\",\n","    \"best_rf = rf_grid.best_estimator_\\n\",\n","    \"rf_score = r2_score(y_test, best_rf.predict(X_test))\\n\",\n","    \"\\n\",\n","    \"print(f'Best RF parameters: {rf_grid.best_params_}')\\n\",\n","    \"print(f'Optimized RF R²: {rf_score:.4f}')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Optimize XGBoost\\n\",\n","    \"print('\\\\nOptimizing XGBoost...')\\n\",\n","    \"\\n\",\n","    \"xgb_param_grid = {\\n\",\n","    \"    'n_estimators': [200, 300, 500],\\n\",\n","    \"    'learning_rate': [0.05, 0.1, 0.15],\\n\",\n","    \"    'max_depth': [4, 6, 8],\\n\",\n","    \"    'min_child_weight': [1, 3, 5],\\n\",\n","    \"    'subsample': [0.8, 0.9, 1.0]\\n\",\n","    \"}\\n\",\n","    \"\\n\",\n","    \"xgb_grid = RandomizedSearchCV(\\n\",\n","    \"    xgb.XGBRegressor(random_state=42),\\n\",\n","    \"    xgb_param_grid,\\n\",\n","    \"    n_iter=15,\\n\",\n","    \"    cv=3,\\n\",\n","    \"    scoring='r2',\\n\",\n","    \"    random_state=42\\n\",\n","    \")\\n\",\n","    \"\\n\",\n","    \"xgb_grid.fit(X_train, y_train)\\n\",\n","    \"best_xgb = xgb_grid.best_estimator_\\n\",\n","    \"xgb_score = r2_score(y_test, best_xgb.predict(X_test))\\n\",\n","    \"\\n\",\n","    \"print(f'Best XGBoost parameters: {xgb_grid.best_params_}')\\n\",\n","    \"print(f'Optimized XGBoost R²: {xgb_score:.4f}')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Optimize Gradient Boosting\\n\",\n","    \"print('\\\\nOptimizing Gradient Boosting...')\\n\",\n","    \"\\n\",\n","    \"gb_param_grid = {\\n\",\n","    \"    'n_estimators': [200, 300, 400],\\n\",\n","    \"    'learning_rate': [0.05, 0.1, 0.15],\\n\",\n","    \"    'max_depth': [4, 6, 8],\\n\",\n","    \"    'min_samples_split': [2, 4, 6],\\n\",\n","    \"    'subsample': [0.8, 0.9, 1.0]\\n\",\n","    \"}\\n\",\n","    \"\\n\",\n","    \"gb_grid = RandomizedSearchCV(\\n\",\n","    \"    GradientBoostingRegressor(random_state=42),\\n\",\n","    \"    gb_param_grid,\\n\",\n","    \"    n_iter=15,\\n\",\n","    \"    cv=3,\\n\",\n","    \"    scoring='r2',\\n\",\n","    \"    random_state=42\\n\",\n","    \")\\n\",\n","    \"\\n\",\n","    \"gb_grid.fit(X_train, y_train)\\n\",\n","    \"best_gb = gb_grid.best_estimator_\\n\",\n","    \"gb_score = r2_score(y_test, best_gb.predict(X_test))\\n\",\n","    \"\\n\",\n","    \"print(f'Best GB parameters: {gb_grid.best_params_}')\\n\",\n","    \"print(f'Optimized GB R²: {gb_score:.4f}')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Advanced Neural Network\\n\",\n","    \"print('\\\\nTraining Advanced Neural Network...')\\n\",\n","    \"\\n\",\n","    \"advanced_nn = MLPRegressor(\\n\",\n","    \"    hidden_layer_sizes=(200, 100, 50),\\n\",\n","    \"    activation='relu',\\n\",\n","    \"    solver='adam',\\n\",\n","    \"    max_iter=2000,\\n\",\n","    \"    early_stopping=True,\\n\",\n","    \"    validation_fraction=0.1,\\n\",\n","    \"    learning_rate_init=0.001,\\n\",\n","    \"    alpha=0.01,\\n\",\n","    \"    random_state=42\\n\",\n","    \")\\n\",\n","    \"\\n\",\n","    \"advanced_nn.fit(X_train_scaled, y_train)\\n\",\n","    \"nn_score = r2_score(y_test, advanced_nn.predict(X_test_scaled))\\n\",\n","    \"\\n\",\n","    \"print(f'Advanced Neural Network R²: {nn_score:.4f}')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"## Ensemble Methods\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Collect optimized models with their scores\\n\",\n","    \"optimized_models = {\\n\",\n","    \"    'Optimized Random Forest': (best_rf, rf_score),\\n\",\n","    \"    'Optimized XGBoost': (best_xgb, xgb_score),\\n\",\n","    \"    'Optimized Gradient Boosting': (best_gb, gb_score),\\n\",\n","    \"    'Advanced Neural Network': (advanced_nn, nn_score)\\n\",\n","    \"}\\n\",\n","    \"\\n\",\n","    \"print('Optimized Model Performance:')\\n\",\n","    \"for name, (model, score) in optimized_models.items():\\n\",\n","    \"    improvement = (score - baseline_r2) / baseline_r2 * 100\\n\",\n","    \"    print(f'{name}: R² = {score:.4f} (+{improvement:.1f}%)')\\n\",\n","    \"\\n\",\n","    \"# Select top 3 models for ensemble\\n\",\n","    \"sorted_models = sorted(optimized_models.items(), key=lambda x: x[1][1], reverse=True)\\n\",\n","    \"top_3_models = sorted_models[:3]\\n\",\n","    \"\\n\",\n","    \"print('\\\\nTop 3 models for ensemble:')\\n\",\n","    \"for name, (model, score) in top_3_models:\\n\",\n","    \"    print(f'- {name}: {score:.4f}')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Create Voting Ensemble\\n\",\n","    \"print('\\\\nCreating Voting Ensemble...')\\n\",\n","    \"\\n\",\n","    \"ensemble_models = []\\n\",\n","    \"for name, (model, score) in top_3_models:\\n\",\n","    \"    # Skip neural network for voting ensemble (different input requirements)\\n\",\n","    \"    if 'Neural Network' not in name:\\n\",\n","    \"        clean_name = name.replace(' ', '_').lower()\\n\",\n","    \"        ensemble_models.append((clean_name, model))\\n\",\n","    \"\\n\",\n","    \"voting_ensemble = None\\n\",\n","    \"voting_score = 0\\n\",\n","    \"\\n\",\n","    \"if len(ensemble_models) >= 2:\\n\",\n","    \"    voting_ensemble = VotingRegressor(ensemble_models)\\n\",\n","    \"    voting_ensemble.fit(X_train, y_train)\\n\",\n","    \"    voting_score = r2_score(y_test, voting_ensemble.predict(X_test))\\n\",\n","    \"    \\n\",\n","    \"    print(f'Voting Ensemble R²: {voting_score:.4f}')\\n\",\n","    \"    print(f'Improvement over baseline: {(voting_score - baseline_r2)/baseline_r2*100:.1f}%')\\nelse:\\n\",\n","    \"    print('Not enough compatible models for voting ensemble')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Create Bagging Ensemble with best model\\n\",\n","    \"print('\\\\nCreating Bagging Ensemble...')\\n\",\n","    \"\\n\",\n","    \"best_single_model = max(optimized_models.items(), key=lambda x: x[1][1])\\n\",\n","    \"best_name, (best_model, best_score) = best_single_model\\n\",\n","    \"\\n\",\n","    \"bagging_ensemble = None\\n\",\n","    \"bagging_score = 0\\n\",\n","    \"\\n\",\n","    \"if 'Neural Network' not in best_name:\\n\",\n","    \"    bagging_ensemble = BaggingRegressor(\\n\",\n","    \"        base_estimator=best_model,\\n\",\n","    \"        n_estimators=10,\\n\",\n","    \"        random_state=42,\\n\",\n","    \"        n_jobs=-1\\n\",\n","    \"    )\\n\",\n","    \"    \\n\",\n","    \"    bagging_ensemble.fit(X_train, y_train)\\n\",\n","    \"    bagging_score = r2_score(y_test, bagging_ensemble.predict(X_test))\\n\",\n","    \"    \\n\",\n","    \"    print(f'Bagging Ensemble R²: {bagging_score:.4f}')\\n\",\n","    \"    print(f'Based on: {best_name}')\\nelse:\\n\",\n","    \"    print('Cannot create bagging ensemble with neural network')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"## Final Model Selection\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Compare all models\\n\",\n","    \"all_results = {}\\n\",\n","    \"\\n\",\n","    \"# Add optimized individual models\\n\",\n","    \"for name, (model, score) in optimized_models.items():\\n\",\n","    \"    all_results[name] = {\\n\",\n","    \"        'model': model,\\n\",\n","    \"        'r2_score': score,\\n\",\n","    \"        'improvement': (score - baseline_r2) / baseline_r2 * 100\\n\",\n","    \"    }\\n\",\n","    \"\\n\",\n","    \"# Add ensemble models\\n\",\n","    \"if voting_ensemble is not None:\\n\",\n","    \"    all_results['Voting Ensemble'] = {\\n\",\n","    \"        'model': voting_ensemble,\\n\",\n","    \"        'r2_score': voting_score,\\n\",\n","    \"        'improvement': (voting_score - baseline_r2) / baseline_r2 * 100\\n\",\n","    \"    }\\n\",\n","    \"\\n\",\n","    \"if bagging_ensemble is not None:\\n\",\n","    \"    all_results['Bagging Ensemble'] = {\\n\",\n","    \"        'model': bagging_ensemble,\\n\",\n","    \"        'r2_score': bagging_score,\\n\",\n","    \"        'improvement': (bagging_score - baseline_r2) / baseline_r2 * 100\\n\",\n","    \"    }\\n\",\n","    \"\\n\",\n","    \"# Find absolute best model\\n\",\n","    \"if all_results:\\n\",\n","    \"    final_best = max(all_results.items(), key=lambda x: x[1]['r2_score'])\\n\",\n","    \"    final_model_name, final_model_info = final_best\\n\",\n","    \"    final_model = final_model_info['model']\\n\",\n","    \"    final_r2 = final_model_info['r2_score']\\n\",\n","    \"else:\\n\",\n","    \"    final_model_name = 'None'\\n\",\n","    \"    final_model = None\\n\",\n","    \"    final_r2 = 0\\n\",\n","    \"\\n\",\n","    \"print('\\\\nFINAL MODEL COMPARISON:')\\n\",\n","    \"print('-' * 60)\\n\",\n","    \"for name, info in sorted(all_results.items(), key=lambda x: x[1]['r2_score'], reverse=True):\\n\",\n","    \"    print(f'{name:25} | R²: {info[\\\"r2_score\\\"]:.4f} | +{info[\\\"improvement\\\"]:5.1f}%')\\n\",\n","    \"\\n\",\n","    \"print('-' * 60)\\n\",\n","    \"print(f'FINAL BEST MODEL: {final_model_name}')\\n\",\n","    \"print(f'Final R²: {final_r2:.4f}')\\n\",\n","    \"print(f'Total improvement over baseline: {(final_r2 - baseline_r2):.4f} ({(final_r2 - baseline_r2)/baseline_r2*100:.1f}%)')\\n\",\n","    \"print(f'Improvement over previous best: {(final_r2 - best_previous_r2):.4f} ({(final_r2 - best_previous_r2)/best_previous_r2*100:.1f}%)')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"## Performance Visualization\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Create comprehensive performance visualization\\n\",\n","    \"if all_results:\\n\",\n","    \"    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\\n\",\n","    \"    \\n\",\n","    \"    # Model comparison bar chart\\n\",\n","    \"    model_names = list(all_results.keys())\\n\",\n","    \"    r2_scores = [info['r2_score'] for info in all_results.values()]\\n\",\n","    \"    colors = ['gold' if name == final_model_name else 'skyblue' for name in model_names]\\n\",\n","    \"    \\n\",\n","    \"    axes[0,0].bar(range(len(model_names)), r2_scores, color=colors)\\n\",\n","    \"    axes[0,0].set_title('Final Model Performance Comparison')\\n\",\n","    \"    axes[0,0].set_ylabel('R² Score')\\n\",\n","    \"    axes[0,0].set_xticks(range(len(model_names)))\\n\",\n","    \"    axes[0,0].set_xticklabels(model_names, rotation=45, ha='right')\\n\",\n","    \"    axes[0,0].axhline(y=baseline_r2, color='red', linestyle='--', label='Baseline')\\n\",\n","    \"    axes[0,0].axhline(y=best_previous_r2, color='orange', linestyle='--', label='Previous Best')\\n\",\n","    \"    axes[0,0].legend()\\n\",\n","    \"    \\n\",\n","    \"    # Improvement over baseline\\n\",\n","    \"    improvements = [info['improvement'] for info in all_results.values()]\\n\",\n","    \"    axes[0,1].bar(range(len(model_names)), improvements, color=colors)\\n\",\n","    \"    axes[0,1].set_title('Improvement over Baseline (%)')\\n\",\n","    \"    axes[0,1].set_ylabel('Improvement (%)')\\n\",\n","    \"    axes[0,1].set_xticks(range(len(model_names)))\\n\",\n","    \"    axes[0,1].set_xticklabels(model_names, rotation=45, ha='right')\\n\",\n","    \"    \\n\",\n","    \"    # Final model predictions vs actual\\n\",\n","    \"    if final_model is not None:\\n\",\n","    \"        if 'Neural Network' in final_model_name:\\n\",\n","    \"            y_pred_final = final_model.predict(X_test_scaled)\\n\",\n","    \"        else:\\n\",\n","    \"            y_pred_final = final_model.predict(X_test)\\n\",\n","    \"        \\n\",\n","    \"        axes[1,0].scatter(y_test, y_pred_final, alpha=0.6, s=20, color='green')\\n\",\n","    \"        axes[1,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\\n\",\n","    \"        axes[1,0].set_xlabel('Actual Viability')\\n\",\n","    \"        axes[1,0].set_ylabel('Predicted Viability')\\n\",\n","    \"        axes[1,0].set_title(f'Final Model: {final_model_name}\\\\nR² = {final_r2:.4f}')\\n\",\n","    \"        axes[1,0].grid(True, alpha=0.3)\\n\",\n","    \"        \\n\",\n","    \"        # Residuals for final model\\n\",\n","    \"        residuals_final = y_test - y_pred_final\\n\",\n","    \"        axes[1,1].scatter(y_pred_final, residuals_final, alpha=0.6, s=20, color='purple')\\n\",\n","    \"        axes[1,1].axhline(y=0, color='r', linestyle='--')\\n\",\n","    \"        axes[1,1].set_xlabel('Predicted Viability')\\n\",\n","    \"        axes[1,1].set_ylabel('Residuals')\\n\",\n","    \"        axes[1,1].set_title('Final Model Residuals')\\n\",\n","    \"        axes[1,1].grid(True, alpha=0.3)\\n\",\n","    \"    \\n\",\n","    \"    plt.tight_layout()\\n\",\n","    \"    plt.show()\\nelse:\\n\",\n","    \"    print('No results to visualize')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"## Cross-Validation Analysis\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Perform cross-validation on final model\\n\",\n","    \"cv_scores = None\\n\",\n","    \"\\n\",\n","    \"if final_model is not None:\\n\",\n","    \"    print('Performing cross-validation on final model...')\\n\",\n","    \"    \\n\",\n","    \"    if 'Neural Network' in final_model_name:\\n\",\n","    \"        cv_scores = cross_val_score(final_model, X_train_scaled, y_train, cv=5, scoring='r2')\\n\",\n","    \"    else:\\n\",\n","    \"        cv_scores = cross_val_score(final_model, X_train, y_train, cv=5, scoring='r2')\\n\",\n","    \"    \\n\",\n","    \"    print(f'\\\\nCross-Validation Results ({final_model_name}):')\\n\",\n","    \"    print(f'Mean CV R²: {cv_scores.mean():.4f}')\\n\",\n","    \"    print(f'Std CV R²: {cv_scores.std():.4f}')\\n\",\n","    \"    print(f'CV Scores: {cv_scores.round(4)}')\\n\",\n","    \"    \\n\",\n","    \"    # Plot CV scores\\n\",\n","    \"    plt.figure(figsize=(10, 6))\\n\",\n","    \"    plt.bar(range(1, len(cv_scores) + 1), cv_scores, alpha=0.7, color='lightblue')\\n\",\n","    \"    plt.axhline(y=cv_scores.mean(), color='red', linestyle='-', label=f'Mean: {cv_scores.mean():.4f}')\\n\",\n","    \"    plt.axhline(y=baseline_r2, color='orange', linestyle='--', label=f'Baseline: {baseline_r2:.4f}')\\n\",\n","    \"    plt.xlabel('CV Fold')\\n\",\n","    \"    plt.ylabel('R² Score')\\n\",\n","    \"    plt.title(f'Cross-Validation Scores - {final_model_name}')\\n\",\n","    \"    plt.legend()\\n\",\n","    \"    plt.grid(True, alpha=0.3)\\n\",\n","    \"    plt.show()\\nelse:\\n\",\n","    \"    print('No final model available for cross-validation')\\n\",\n","    \"    cv_scores = np.array([0])\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"## Save Final Improved Model\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Create directories\\n\",\n","    \"os.makedirs('../models', exist_ok=True)\\n\",\n","    \"os.makedirs('../data/processed', exist_ok=True)\\n\",\n","    \"\\n\",\n","    \"if final_model is not None and cv_scores is not None:\\n\",\n","    \"    # Save the final optimized model\\n\",\n","    \"    final_model_filename = 'final_optimized_model.pkl'\\n\",\n","    \"    with open(f'../models/{final_model_filename}', 'wb') as f:\\n\",\n","    \"        pickle.dump(final_model, f)\\n\",\n","    \"    \\n\",\n","    \"    # Save the scaler\\n\",\n","    \"    with open('../models/final_scaler.pkl', 'wb') as f:\\n\",\n","    \"        pickle.dump(scaler, f)\\n\",\n","    \"    \\n\",\n","    \"    # Save final model info\\n\",\n","    \"    final_model_info = {\\n\",\n","    \"        'final_model_name': final_model_name,\\n\",\n","    \"        'final_r2': float(final_r2),\\n\",\n","    \"        'baseline_r2': float(baseline_r2),\\n\",\n","    \"        'previous_best_r2': float(best_previous_r2),\\n\",\n","    \"        'total_improvement': float(final_r2 - baseline_r2),\\n\",\n","    \"        'total_improvement_percent': float((final_r2 - baseline_r2) / baseline_r2 * 100),\\n\",\n","    \"        'additional_improvement': float(final_r2 - best_previous_r2),\\n\",\n","    \"        'additional_improvement_percent': float((final_r2 - best_previous_r2) / best_previous_r2 * 100),\\n\",\n","    \"        'cv_mean': float(cv_scores.mean()),\\n\",\n","    \"        'cv_std': float(cv_scores.std()),\\n\",\n","    \"        'training_samples': len(X_train),\\n\",\n","    \"        'test_samples': len(X_test),\\n\",\n","    \"        'hyperparameter_optimization': True,\\n\",\n","    \"        'ensemble_methods_used': voting_ensemble is not None or bagging_ensemble is not None\\n\",\n","    \"    }\\n\",\n","    \"    \\n\",\n","    \"    # Save all model results\\n\",\n","    \"    all_model_results = {}\\n\",\n","    \"    for name, info in all_results.items():\\n\",\n","    \"        all_model_results[name] = {\\n\",\n","    \"            'r2_score': float(info['r2_score']),\\n\",\n","    \"            'improvement_percent': float(info['improvement'])\\n\",\n","    \"        }\\n\",\n","    \"    \\n\",\n","    \"    final_results = {\\n\",\n","    \"        'final_model_info': final_model_info,\\n\",\n","    \"        'all_model_results': all_model_results,\\n\",\n","    \"        'optimization_summary': {\\n\",\n","    \"            'random_forest_optimized': True,\\n\",\n","    \"            'xgboost_optimized': True,\\n\",\n","    \"            'gradient_boosting_optimized': True,\\n\",\n","    \"            'neural_network_advanced': True,\\n\",\n","    \"            'voting_ensemble': voting_ensemble is not None,\\n\",\n","    \"            'bagging_ensemble': bagging_ensemble is not None\\n\",\n","    \"        }\\n\",\n","    \"    }\\n\",\n","    \"    \\n\",\n","    \"    with open('../data/processed/final_model_results.json', 'w') as f:\\n\",\n","    \"        json.dump(final_results, f, indent=2)\\n\",\n","    \"    \\n\",\n","    \"    print('Final optimized model and results saved!')\\n\",\n","    \"    print('\\\\nFiles saved:')\\n\",\n","    \"    print('- final_optimized_model.pkl (final model)')\\n\",\n","    \"    print('- final_scaler.pkl (scaler for final model)')\\n\",\n","    \"    print('- final_model_results.json (comprehensive results)')\\n\",\n","    \"    \\n\",\n","    \"    print('\\\\nFINAL OPTIMIZATION SUMMARY:')\\n\",\n","    \"    print('=' * 40)\\n\",\n","    \"    print(f'Baseline R²:          {baseline_r2:.4f}')\\n\",\n","    \"    print(f'Previous Best R²:     {best_previous_r2:.4f} ({best_previous_model})')\\n\",\n","    \"    print(f'Final Optimized R²:   {final_r2:.4f} ({final_model_name})')\\n\",\n","    \"    print('-' * 40)\\n\",\n","    \"    print(f'Total Improvement:    +{final_r2 - baseline_r2:.4f} ({(final_r2 - baseline_r2)/baseline_r2*100:.1f}%)')\\n\",\n","    \"    print(f'Additional Improvement: +{final_r2 - best_previous_r2:.4f} ({(final_r2 - best_previous_r2)/best_previous_r2*100:.1f}%)')\\n\",\n","    \"    print(f'Cross-Validation:     {cv_scores.mean():.4f} ± {cv_scores.std():.4f}')\\n\",\n","    \"    print('=' * 40)\\nelse:\\n\",\n","    \"    print('No valid final model to save')\"\n","   ]\n","  }\n"," ],\n"," \"metadata\": {\n","  \"kernelspec\": {\n","   \"display_name\": \"Python 3\",\n","   \"language\": \"python\",\n","   \"name\": \"python3\"\n","  },\n","  \"language_info\": {\n","   \"codemirror_mode\": {\n","    \"name\": \"ipython\",\n","    \"version\": 3\n","   },\n","   \"file_extension\": \".py\",\n","   \"mimetype\": \"text/x-python\",\n","   \"name\": \"python\",\n","   \"nbconvert_exporter\": \"python\",\n","   \"pygments_lexer\": \"ipython3\",\n","   \"version\": \"3.8.5\"\n","  }\n"," },\n"," \"nbformat\": 4,\n"," \"nbformat_minor\": 4\n","}"]}]}