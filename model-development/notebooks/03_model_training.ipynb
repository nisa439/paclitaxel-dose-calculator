{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOjsSlOKorp3V2JR4utGFNx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"W1B_yRszmE3z"},"outputs":[],"source":["{\n"," \"cells\": [\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"# Paclitaxel Dose Optimization - Model Training\\n\",\n","    \"\\n\",\n","    \"This notebook covers:\\n\",\n","    \"1. Loading enhanced features from previous step\\n\",\n","    \"2. Baseline model training\\n\",\n","    \"3. Multiple algorithm comparison\\n\",\n","    \"4. Model performance evaluation\\n\",\n","    \"5. Feature importance analysis\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Import required libraries\\n\",\n","    \"import pandas as pd\\n\",\n","    \"import numpy as np\\n\",\n","    \"import matplotlib.pyplot as plt\\n\",\n","    \"import seaborn as sns\\n\",\n","    \"from sklearn.model_selection import train_test_split, cross_val_score\\n\",\n","    \"from sklearn.preprocessing import StandardScaler\\n\",\n","    \"from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\\n\",\n","    \"from sklearn.linear_model import LinearRegression\\n\",\n","    \"from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\\n\",\n","    \"from sklearn.neural_network import MLPRegressor\\n\",\n","    \"import xgboost as xgb\\n\",\n","    \"import pickle\\n\",\n","    \"import json\\n\",\n","    \"import os\\n\",\n","    \"import warnings\\n\",\n","    \"warnings.filterwarnings('ignore')\\n\",\n","    \"\\n\",\n","    \"print('Libraries imported for model training!')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Load enhanced data from previous step\\n\",\n","    \"X_enhanced = pd.read_csv('../data/processed/X_enhanced.csv')\\n\",\n","    \"y = pd.read_csv('../data/processed/y_enhanced.csv').squeeze()\\n\",\n","    \"\\n\",\n","    \"# Load feature list\\n\",\n","    \"with open('../data/processed/enhanced_features.txt', 'r') as f:\\n\",\n","    \"    enhanced_features = [line.strip() for line in f.readlines()]\\n\",\n","    \"\\n\",\n","    \"print('Enhanced dataset loaded:')\\n\",\n","    \"print(f'Features shape: {X_enhanced.shape}')\\n\",\n","    \"print(f'Target shape: {y.shape}')\\n\",\n","    \"print(f'Enhanced features: {enhanced_features}')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"## Baseline Model with Original Features\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Create baseline with original simple features\\n\",\n","    \"X_simple = X_enhanced[['log_dose', 'cell_line_encoded']]\\n\",\n","    \"\\n\",\n","    \"# Split data for baseline\\n\",\n","    \"X_train_simple, X_test_simple, y_train, y_test = train_test_split(\\n\",\n","    \"    X_simple, y, test_size=0.2, random_state=42\\n\",\n","    \")\\n\",\n","    \"\\n\",\n","    \"# Train baseline model\\n\",\n","    \"baseline_model = RandomForestRegressor(n_estimators=100, random_state=42)\\n\",\n","    \"baseline_model.fit(X_train_simple, y_train)\\n\",\n","    \"y_pred_baseline = baseline_model.predict(X_test_simple)\\n\",\n","    \"baseline_r2 = r2_score(y_test, y_pred_baseline)\\n\",\n","    \"baseline_rmse = np.sqrt(mean_squared_error(y_test, y_pred_baseline))\\n\",\n","    \"\\n\",\n","    \"print('Baseline Model Performance (Original Features):')\\n\",\n","    \"print(f'   R² Score: {baseline_r2:.4f}')\\n\",\n","    \"print(f'   RMSE: {baseline_rmse:.4f}')\\n\",\n","    \"print(f'   Features used: {X_simple.columns.tolist()}')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"## Enhanced Model Training\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Split enhanced data\\n\",\n","    \"X_train, X_test, y_train_enh, y_test_enh = train_test_split(\\n\",\n","    \"    X_enhanced, y, test_size=0.2, random_state=42\\n\",\n","    \")\\n\",\n","    \"\\n\",\n","    \"# Scale features for neural network\\n\",\n","    \"scaler = StandardScaler()\\n\",\n","    \"X_train_scaled = scaler.fit_transform(X_train)\\n\",\n","    \"X_test_scaled = scaler.transform(X_test)\\n\",\n","    \"\\n\",\n","    \"print('Enhanced dataset split:')\\n\",\n","    \"print(f'Training set: {X_train.shape}')\\n\",\n","    \"print(f'Test set: {X_test.shape}')\\n\",\n","    \"print(f'Features: {len(enhanced_features)}')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"## Multi-Algorithm Comparison\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Define models to compare\\n\",\n","    \"models = {\\n\",\n","    \"    'Linear Regression': LinearRegression(),\\n\",\n","    \"    'Random Forest': RandomForestRegressor(\\n\",\n","    \"        n_estimators=200, max_depth=12, min_samples_split=5,\\n\",\n","    \"        min_samples_leaf=2, random_state=42, n_jobs=-1\\n\",\n","    \"    ),\\n\",\n","    \"    'Enhanced Random Forest': RandomForestRegressor(\\n\",\n","    \"        n_estimators=500, max_depth=15, min_samples_split=3,\\n\",\n","    \"        min_samples_leaf=1, random_state=42, n_jobs=-1\\n\",\n","    \"    ),\\n\",\n","    \"    'Gradient Boosting': GradientBoostingRegressor(\\n\",\n","    \"        n_estimators=200, learning_rate=0.1, max_depth=6,\\n\",\n","    \"        min_samples_split=4, random_state=42\\n\",\n","    \"    ),\\n\",\n","    \"    'XGBoost': xgb.XGBRegressor(\\n\",\n","    \"        n_estimators=200, learning_rate=0.1, max_depth=6,\\n\",\n","    \"        min_child_weight=1, random_state=42\\n\",\n","    \"    ),\\n\",\n","    \"    'Neural Network': MLPRegressor(\\n\",\n","    \"        hidden_layer_sizes=(100, 50), activation='relu', solver='adam',\\n\",\n","    \"        max_iter=1000, random_state=42, early_stopping=True\\n\",\n","    \"    )\\n\",\n","    \"}\\n\",\n","    \"\\n\",\n","    \"print(f'Training {len(models)} different algorithms...')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Train and evaluate models\\n\",\n","    \"model_results = {}\\n\",\n","    \"trained_models = {}\\n\",\n","    \"\\n\",\n","    \"for name, model in models.items():\\n\",\n","    \"    print(f'\\\\nTraining {name}...')\\n\",\n","    \"    \\n\",\n","    \"    try:\\n\",\n","    \"        # Train model\\n\",\n","    \"        if name == 'Neural Network':\\n\",\n","    \"            model.fit(X_train_scaled, y_train_enh)\\n\",\n","    \"            y_pred_train = model.predict(X_train_scaled)\\n\",\n","    \"            y_pred_test = model.predict(X_test_scaled)\\n\",\n","    \"        else:\\n\",\n","    \"            model.fit(X_train, y_train_enh)\\n\",\n","    \"            y_pred_train = model.predict(X_train)\\n\",\n","    \"            y_pred_test = model.predict(X_test)\\n\",\n","    \"        \\n\",\n","    \"        # Calculate metrics\\n\",\n","    \"        train_r2 = r2_score(y_train_enh, y_pred_train)\\n\",\n","    \"        test_r2 = r2_score(y_test_enh, y_pred_test)\\n\",\n","    \"        train_rmse = np.sqrt(mean_squared_error(y_train_enh, y_pred_train))\\n\",\n","    \"        test_rmse = np.sqrt(mean_squared_error(y_test_enh, y_pred_test))\\n\",\n","    \"        \\n\",\n","    \"        # Cross-validation\\n\",\n","    \"        try:\\n\",\n","    \"            if name == 'Neural Network':\\n\",\n","    \"                cv_scores = cross_val_score(model, X_train_scaled, y_train_enh, cv=3, scoring='r2')\\n\",\n","    \"            else:\\n\",\n","    \"                cv_scores = cross_val_score(model, X_train, y_train_enh, cv=3, scoring='r2')\\n\",\n","    \"        except:\\n\",\n","    \"            cv_scores = np.array([test_r2])\\n\",\n","    \"        \\n\",\n","    \"        model_results[name] = {\\n\",\n","    \"            'Train R²': train_r2,\\n\",\n","    \"            'Test R²': test_r2,\\n\",\n","    \"            'Train RMSE': train_rmse,\\n\",\n","    \"            'Test RMSE': test_rmse,\\n\",\n","    \"            'CV R² Mean': cv_scores.mean(),\\n\",\n","    \"            'CV R² Std': cv_scores.std()\\n\",\n","    \"        }\\n\",\n","    \"        \\n\",\n","    \"        trained_models[name] = model\\n\",\n","    \"        \\n\",\n","    \"        # Calculate improvement over baseline\\n\",\n","    \"        improvement = (test_r2 - baseline_r2) / baseline_r2 * 100\\n\",\n","    \"        print(f'{name} - Test R²: {test_r2:.4f}, Improvement: {improvement:+.1f}%')\\n\",\n","    \"        \\n\",\n","    \"    except Exception as e:\\n\",\n","    \"        print(f'{name} failed: {e}')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Display comprehensive results\\n\",\n","    \"results_df = pd.DataFrame(model_results).T\\n\",\n","    \"\\n\",\n","    \"# Add baseline for comparison\\n\",\n","    \"baseline_row = pd.DataFrame({\\n\",\n","    \"    'Train R²': [baseline_r2],\\n\",\n","    \"    'Test R²': [baseline_r2],\\n\",\n","    \"    'Train RMSE': [baseline_rmse],\\n\",\n","    \"    'Test RMSE': [baseline_rmse],\\n\",\n","    \"    'CV R² Mean': [baseline_r2],\\n\",\n","    \"    'CV R² Std': [0.0]\\n\",\n","    \"}, index=['Baseline (Original)'])\\n\",\n","    \"\\n\",\n","    \"comparison_df = pd.concat([baseline_row, results_df])\\n\",\n","    \"\\n\",\n","    \"print('\\\\nComplete Model Comparison:')\\n\",\n","    \"print(comparison_df.round(4))\\n\",\n","    \"\\n\",\n","    \"# Find best model\\n\",\n","    \"if len(trained_models) > 0:\\n\",\n","    \"    best_model_name = results_df['Test R²'].idxmax()\\n\",\n","    \"    best_model = trained_models[best_model_name]\\n\",\n","    \"    best_r2 = results_df.loc[best_model_name, 'Test R²']\\n\",\n","    \"    \\n\",\n","    \"    print(f'\\\\nBest Model: {best_model_name}')\\n\",\n","    \"    print(f'Test R²: {best_r2:.4f}')\\n\",\n","    \"    print(f'Improvement over baseline: {best_r2 - baseline_r2:.4f} ({(best_r2 - baseline_r2)/baseline_r2*100:.1f}%)')\\nelse:\\n\",\n","    \"    print('No models were successfully trained')\\n\",\n","    \"    best_model_name = 'None'\\n\",\n","    \"    best_model = None\\n\",\n","    \"    best_r2 = 0\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"## Model Performance Visualization\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Plot model comparison\\n\",\n","    \"fig, axes = plt.subplots(2, 2, figsize=(15, 12))\\n\",\n","    \"\\n\",\n","    \"# R² comparison\\n\",\n","    \"r2_scores = comparison_df['Test R²']\\n\",\n","    \"colors = ['red' if 'Baseline' in idx else 'skyblue' for idx in r2_scores.index]\\n\",\n","    \"axes[0,0].bar(range(len(r2_scores)), r2_scores.values, color=colors)\\n\",\n","    \"axes[0,0].set_title('Model R² Score Comparison')\\n\",\n","    \"axes[0,0].set_ylabel('R² Score')\\n\",\n","    \"axes[0,0].set_xticks(range(len(r2_scores)))\\n\",\n","    \"axes[0,0].set_xticklabels(r2_scores.index, rotation=45, ha='right')\\n\",\n","    \"axes[0,0].axhline(y=baseline_r2, color='red', linestyle='--', label='Baseline')\\n\",\n","    \"axes[0,0].legend()\\n\",\n","    \"\\n\",\n","    \"# RMSE comparison\\n\",\n","    \"rmse_scores = comparison_df['Test RMSE']\\n\",\n","    \"axes[0,1].bar(range(len(rmse_scores)), rmse_scores.values, color=colors)\\n\",\n","    \"axes[0,1].set_title('Model RMSE Comparison')\\n\",\n","    \"axes[0,1].set_ylabel('RMSE')\\n\",\n","    \"axes[0,1].set_xticks(range(len(rmse_scores)))\\n\",\n","    \"axes[0,1].set_xticklabels(rmse_scores.index, rotation=45, ha='right')\\n\",\n","    \"\\n\",\n","    \"# Training vs Test R² (exclude baseline)\\n\",\n","    \"if len(results_df) > 0:\\n\",\n","    \"    for model_name in results_df.index:\\n\",\n","    \"        train_r2 = results_df.loc[model_name, 'Train R²']\\n\",\n","    \"        test_r2 = results_df.loc[model_name, 'Test R²']\\n\",\n","    \"        axes[1,0].scatter(train_r2, test_r2, s=100, label=model_name, alpha=0.7)\\n\",\n","    \"    \\n\",\n","    \"    # Perfect line\\n\",\n","    \"    min_r2 = min(results_df['Train R²'].min(), results_df['Test R²'].min())\\n\",\n","    \"    max_r2 = max(results_df['Train R²'].max(), results_df['Test R²'].max())\\n\",\n","    \"    axes[1,0].plot([min_r2, max_r2], [min_r2, max_r2], 'k--', alpha=0.5)\\n\",\n","    \"    axes[1,0].set_title('Training vs Test R² (Overfitting Check)')\\n\",\n","    \"    axes[1,0].set_xlabel('Training R²')\\n\",\n","    \"    axes[1,0].set_ylabel('Test R²')\\n\",\n","    \"    axes[1,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\\n\",\n","    \"\\n\",\n","    \"# Cross-validation scores\\n\",\n","    \"if len(results_df) > 0:\\n\",\n","    \"    cv_means = results_df['CV R² Mean']\\n\",\n","    \"    cv_stds = results_df['CV R² Std']\\n\",\n","    \"    axes[1,1].bar(range(len(cv_means)), cv_means.values, \\n\",\n","    \"                  yerr=cv_stds.values, capsize=5, alpha=0.7)\\n\",\n","    \"    axes[1,1].set_title('Cross-Validation R² Scores')\\n\",\n","    \"    axes[1,1].set_ylabel('CV R² Score')\\n\",\n","    \"    axes[1,1].set_xticks(range(len(cv_means)))\\n\",\n","    \"    axes[1,1].set_xticklabels(cv_means.index, rotation=45, ha='right')\\n\",\n","    \"\\n\",\n","    \"plt.tight_layout()\\n\",\n","    \"plt.show()\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"## Feature Importance Analysis\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Feature importance for tree-based models\\n\",\n","    \"feature_importance = None\\n\",\n","    \"\\n\",\n","    \"if best_model is not None and hasattr(best_model, 'feature_importances_'):\\n\",\n","    \"    feature_importance = pd.DataFrame({\\n\",\n","    \"        'feature': enhanced_features,\\n\",\n","    \"        'importance': best_model.feature_importances_\\n\",\n","    \"    }).sort_values('importance', ascending=False)\\n\",\n","    \"    \\n\",\n","    \"    print(f'Feature Importance Analysis ({best_model_name}):')\\n\",\n","    \"    print(feature_importance)\\n\",\n","    \"    \\n\",\n","    \"    # Plot feature importance\\n\",\n","    \"    plt.figure(figsize=(12, 8))\\n\",\n","    \"    top_features = feature_importance.head(12)\\n\",\n","    \"    plt.barh(range(len(top_features)), top_features['importance'])\\n\",\n","    \"    plt.yticks(range(len(top_features)), top_features['feature'])\\n\",\n","    \"    plt.xlabel('Feature Importance')\\n\",\n","    \"    plt.title(f'Top 12 Feature Importances ({best_model_name})')\\n\",\n","    \"    plt.gca().invert_yaxis()\\n\",\n","    \"    plt.tight_layout()\\n\",\n","    \"    plt.show()\\nelse:\\n\",\n","    \"    print(f'Feature importance not available for {best_model_name}')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"## Prediction Analysis\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Get predictions from best model\\n\",\n","    \"if best_model is not None:\\n\",\n","    \"    if best_model_name == 'Neural Network':\\n\",\n","    \"        y_pred_best = best_model.predict(X_test_scaled)\\n\",\n","    \"    else:\\n\",\n","    \"        y_pred_best = best_model.predict(X_test)\\n\",\n","    \"    \\n\",\n","    \"    # Prediction vs Actual plot\\n\",\n","    \"    plt.figure(figsize=(10, 8))\\n\",\n","    \"    plt.scatter(y_test_enh, y_pred_best, alpha=0.6, s=20)\\n\",\n","    \"    plt.plot([y_test_enh.min(), y_test_enh.max()], [y_test_enh.min(), y_test_enh.max()], 'r--', lw=2)\\n\",\n","    \"    plt.xlabel('Actual Viability')\\n\",\n","    \"    plt.ylabel('Predicted Viability')\\n\",\n","    \"    plt.title(f'Prediction vs Actual ({best_model_name})\\\\nR² = {best_r2:.4f}')\\n\",\n","    \"    plt.grid(True, alpha=0.3)\\n\",\n","    \"    plt.show()\\n\",\n","    \"    \\n\",\n","    \"    # Residuals plot\\n\",\n","    \"    residuals = y_test_enh - y_pred_best\\n\",\n","    \"    plt.figure(figsize=(10, 6))\\n\",\n","    \"    plt.scatter(y_pred_best, residuals, alpha=0.6, s=20)\\n\",\n","    \"    plt.axhline(y=0, color='r', linestyle='--')\\n\",\n","    \"    plt.xlabel('Predicted Viability')\\n\",\n","    \"    plt.ylabel('Residuals')\\n\",\n","    \"    plt.title(f'Residuals Plot ({best_model_name})')\\n\",\n","    \"    plt.grid(True, alpha=0.3)\\n\",\n","    \"    plt.show()\\nelse:\\n\",\n","    \"    print('No valid model for prediction analysis')\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"markdown\",\n","   \"metadata\": {},\n","   \"source\": [\n","    \"## Save Best Model and Results\"\n","   ]\n","  },\n","  {\n","   \"cell_type\": \"code\",\n","   \"execution_count\": null,\n","   \"metadata\": {},\n","   \"outputs\": [],\n","   \"source\": [\n","    \"# Create directories\\n\",\n","    \"os.makedirs('../models', exist_ok=True)\\n\",\n","    \"os.makedirs('../data/processed', exist_ok=True)\\n\",\n","    \"\\n\",\n","    \"if best_model is not None:\\n\",\n","    \"    # Save best model\\n\",\n","    \"    model_filename = best_model_name.lower().replace(' ', '_') + '_model.pkl'\\n\",\n","    \"    with open(f'../models/{model_filename}', 'wb') as f:\\n\",\n","    \"        pickle.dump(best_model, f)\\n\",\n","    \"    \\n\",\n","    \"    # Save scaler\\n\",\n","    \"    with open('../models/scaler.pkl', 'wb') as f:\\n\",\n","    \"        pickle.dump(scaler, f)\\n\",\n","    \"    \\n\",\n","    \"    # Save results\\n\",\n","    \"    comparison_df.to_csv('../data/processed/model_comparison_results.csv')\\n\",\n","    \"    \\n\",\n","    \"    if feature_importance is not None:\\n\",\n","    \"        feature_importance.to_csv('../data/processed/feature_importance.csv', index=False)\\n\",\n","    \"    \\n\",\n","    \"    # Save model info\\n\",\n","    \"    model_info = {\\n\",\n","    \"        'best_model': best_model_name,\\n\",\n","    \"        'best_r2': float(best_r2),\\n\",\n","    \"        'baseline_r2': float(baseline_r2),\\n\",\n","    \"        'improvement': float(best_r2 - baseline_r2),\\n\",\n","    \"        'improvement_percent': float((best_r2 - baseline_r2) / baseline_r2 * 100),\\n\",\n","    \"        'training_samples': len(X_train),\\n\",\n","    \"        'test_samples': len(X_test),\\n\",\n","    \"        'enhanced_features': enhanced_features\\n\",\n","    \"    }\\n\",\n","    \"    \\n\",\n","    \"    with open('../data/processed/model_info.json', 'w') as f:\\n\",\n","    \"        json.dump(model_info, f, indent=2)\\n\",\n","    \"    \\n\",\n","    \"    print('Best model and results saved!')\\n\",\n","    \"    print('Files saved:')\\n\",\n","    \"    print(f'  - {model_filename} (best model)')\\n\",\n","    \"    print('  - scaler.pkl (feature scaler)')\\n\",\n","    \"    print('  - model_comparison_results.csv (all model results)')\\n\",\n","    \"    if feature_importance is not None:\\n\",\n","    \"        print('  - feature_importance.csv (feature importance)')\\n\",\n","    \"    print('  - model_info.json (model metadata)')\\n\",\n","    \"    \\n\",\n","    \"    print(f'\\\\nTRAINING SUMMARY:')\\n\",\n","    \"    print(f'   Best Model: {best_model_name}')\\n\",\n","    \"    print(f'   Baseline R²: {baseline_r2:.4f}')\\n\",\n","    \"    print(f'   Best R²: {best_r2:.4f}')\\n\",\n","    \"    print(f'   Improvement: +{best_r2 - baseline_r2:.4f} ({(best_r2 - baseline_r2)/baseline_r2*100:.1f}%)')\\n\",\n","    \"    print(f'   Features: {len(enhanced_features)} enhanced features')\\nelse:\\n\",\n","    \"    print('No valid model to save')\"\n","   ]\n","  }\n"," ],\n"," \"metadata\": {\n","  \"kernelspec\": {\n","   \"display_name\": \"Python 3\",\n","   \"language\": \"python\",\n","   \"name\": \"python3\"\n","  },\n","  \"language_info\": {\n","   \"codemirror_mode\": {\n","    \"name\": \"ipython\",\n","    \"version\": 3\n","   },\n","   \"file_extension\": \".py\",\n","   \"mimetype\": \"text/x-python\",\n","   \"name\": \"python\",\n","   \"nbconvert_exporter\": \"python\",\n","   \"pygments_lexer\": \"ipython3\",\n","   \"version\": \"3.8.5\"\n","  }\n"," },\n"," \"nbformat\": 4,\n"," \"nbformat_minor\": 4\n","}"]}]}